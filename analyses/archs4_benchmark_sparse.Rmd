---
title: "progeny_dorothea_downsampling"
author: "Christian Holland"
date: "24/09/2018"
output: html_document
---
```{r "knitr config", cache=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::knit(..., quiet = TRUE)
```
### Libraries and sources
These libraries and sources are used in this analysis 
```{r "setup", message=F}
library(scran)
library(tidyverse)
library(yardstick)
library(tidylog)
library(furrr)
library(edgeR)
library(viper)
library(Matrix)
library(myutils)
library(ggrepel)
library(Rtsne)
library(cluster)
library(tidytext)

source("src/my_ggplot_themes.R")
source("src/downsampling_strategies.R")

options("tidylog.display" = list(print))
options(future.globals.maxSize= 2097152000) # corresponds to 2 GB

plan(multiprocess)
```
### Basic Pipeline
#### Parse benchmark meta data from ChEA3
```{r "parse benchmark meta data from ChEA3"}
df = read_delim("data/archs4_benchmark/meta_data/Single-TF_Perturbations.gmt", 
                delim="\t", col_names = F) %>%
  select(id = X1)

dorothea_tfs = read_csv(
  "data/regulons/dorothea/dorothea_regulon_human_v1.csv"
  ) %>%
  distinct(tf, confidence) %>%
  rename(target = tf)

knockdown_alias = c("SIRNA", "KO", "SHRNA", "KD")
overexpression_alias = c("ACTIVATION", "OE", "HYPERACTIVE")

meta_df = df %>%
  filter(str_detect(id, "RNASEQ")) %>%
  pull(id) %>%
  str_match(
    "^([0-9A-Z]*)_([A-Z]*)_([0-9A-Z]*)_HUMAN_(GSE\\d*)_([0-9A-Z]*).*RNASEQ"
    ) %>%
  as.data.frame() %>%
  setNames(
    ., c("description", "target", "perturbation", "molecule", "accession", "other")
    ) %>%
  na_if("") %>%
  as_tibble() %>%
  mutate(perturbation = case_when(perturbation %in% knockdown_alias ~ "inhibition",
                   perturbation %in% overexpression_alias ~ "activation")) %>%
  mutate(id = paste0("archs:", str_pad(row_number(),4, pad=0))) %>%
  mutate(class = "single_tf_perturbation") %>%
  inner_join(dorothea_tfs)

saveRDS(meta_df, "data/archs4_benchmark/meta_data/meta_df.rds")
```

#### Unzip and rename achives manually downloaded from ARCHS4
```{r "unzip and rename achives"}
zips = list.files("data/archs4_benchmark/count_data", full.names = T, 
                  pattern = "*zip") %>%
  map(function(archive) {
    accession = str_match(archive, "GSE\\d*")
    path = file.path("data", "archs4_benchmark", "count_data")
    unzip(archive, exdir = path)
    file.rename(paste0(path, "/gene_count.tsv"),
                paste0(path, "/", accession, ".tsv"))
  })
```

#### Tidy manually curated sample annotation file
```{r "tidy manually curated sample annotation file"}
raw_anno = read_delim("data/archs4_benchmark/meta_data/sample_annotations.csv", delim = ";") %>%
  gather(group, sample, -id) %>%
  separate_rows(sample, sep="[|]") %>%
  arrange(id, sample) %>%
  drop_na(sample)

anno_bulk = raw_anno %>%
  mutate(type = "bulk_sample")

anno_sc = raw_anno %>%
  mutate(n = 100) %>%
  uncount(n) %>%
  group_by(id, sample) %>%
  mutate(cell_num = 1:100) %>%
  ungroup() %>%
  transmute(id, group, sample, cell = str_c(sample, "_cell_", str_pad(cell_num, nchar(100)+1, pad=0))) %>%
  mutate(type = "single_cells")

bind_rows(anno_bulk, anno_sc) %>%
  saveRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds")
```

#### Load count data and map samples to perturbation experiments
```{r "load count data and sample samples"}
anno = readRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds") %>%
  filter(type == "bulk_sample")
meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds")
meta_df = inner_join(meta,anno, by="id") %>%
  select(id, accession, group, sample)

tidy_counts = list.files("data/archs4_benchmark/count_data", pattern="*tsv", full.names = T) %>%
  map_df(function(path) {
    accession = path %>%
      basename() %>%
      tools::file_path_sans_ext()
    
    read_delim(path, delim="\t") %>%
      rename(gene = X1) %>%
      gather(sample, count, -gene) %>%
      mutate(accession = accession)
  }) %>%
  inner_join(meta_df, by = c("sample", "accession")) %>%
  select(id, sample, group, gene, count)

# double check whether the mapping of samples is correct
a = meta_df %>% 
  count(id, group) %>%
  mutate_if(is.factor, as.character)
b = tidy_counts %>% 
  distinct(id,  group, sample) %>% 
  count(id, group) %>%
  mutate_if(is.factor, as.character)

stopifnot(identical(a,b))
anti_join(a,b)
anti_join(b,a)

saveRDS(tidy_counts, "data/archs4_benchmark/mapped_count_data.rds")
```
#### Simulation of single cells
```{r "simulate single cells"}
pcg = readRDS("output/transcript_downsampling/gene_lengths.rds") %>%
  select(gene)
counts = readRDS("data/archs4_benchmark/mapped_count_data.rds") %>%
  inner_join(pcg, by="gene") %>%
  select(-group)

set.seed(12345)
tmp = counts %>%
  mutate(gene = as_factor(gene)) %>%
  nest(-id, -sample, .key="bulk_sample") %>%
  arrange(id, sample) %>%
  mutate(num_cells = 100) %>%
  mutate(single_cells = future_pmap(., .f = generate_single_cells4, 
                                    .progress = T)) %>%
  gather(type, raw_counts, bulk_sample, single_cells)


# merge bulk samples to a single matrix per experiemt (archs:xxxx)
sparse_matrix_bulk = tmp %>% 
  filter(type == "bulk_sample") %>%
  unnest() %>%
  nest(-c(id, num_cells, type)) %>%
  transmute(id, num_cells, type, raw_counts = data %>% map(function(i) {
    i %>%
      spread(sample, count) %>%
      data.frame(row.names=1, check.names = F, stringsAsFactors = F) %>%
      as.matrix()
  }))

# merge single cells to a single sparse matrix per experiment (archs:xxxx) 
sparse_matrix_sc = tmp %>%
  filter(type == "single_cells") %>%
  nest(-c(id, num_cells, type)) %>%
  transmute(id, num_cells, type, raw_counts = data %>% map(function(i) {
    i %>%
      select(-sample) %>%
      pull(raw_counts) %>%
      reduce(cbind)
  }))

res = bind_rows(sparse_matrix_sc, sparse_matrix_bulk)

saveRDS(res, "output/archs4_benchmark/raw_read_counts_sparse.rds")
```

#### Create design matrices required for bulk RNAseq normalization
```{r "create design matrices required for bulk rnaseq normalization"}
anno = readRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds") %>%
  mutate(group = as_factor(group))
design_df = anno %>% nest(-c(id, type)) %>%
  transmute(id, type, design = pmap(., .f=function(data, type, ...) {
    if (type == "bulk_sample") {
      design_matrix = data %>%
        arrange(sample) %>%
        model.matrix(~0+group, data=.)
    
      rownames(design_matrix) = data$sample
      colnames(design_matrix) = levels(data$group)
    } else if (type == "single_cells") {
      design_matrix = data %>%
        arrange(cell) %>%
        model.matrix(~0+group, data=.)
    
      rownames(design_matrix) = data$sample
      colnames(design_matrix) = levels(data$group)
    }
    return(design_matrix)
  }))

saveRDS(design_df, "data/archs4_benchmark/meta_data/design_df.rds")
```

#### Normalization
```{r "normalization"}
design_df = readRDS("data/archs4_benchmark/meta_data/design_df.rds")
df = readRDS("output/archs4_benchmark/raw_read_counts_sparse.rds")
  
norm_expr = df %>% 
  left_join(design_df, by=c("id", "type")) #%>%
  transmute(id, type, emat = pmap(., .f=function(raw_counts, type, id, design, ...) {
    message(id, " - ", type)
    if (type == "single_cells") {
      
      sce = SingleCellExperiment(list(counts=raw_counts)) %>%
        computeSumFactors() %>%
        normalize() %>%
        exprs()
      
    } else if (type == "bulk_sample") {
      norm_count_matrix = raw_counts %>%
        DGEList() %>%
        calcNormFactors() %>%
        voom(design = design) %>%
        pluck("E")
    }
  }))

saveRDS(norm_expr, "output/archs4_benchmark/normalized_data_sparse.rds")
```

#### Calculation of logFC with limma
```{r "calculation of logfc with limma}
design_df = readRDS("data/archs4_benchmark/meta_data/design_df.rds")
norm_expr = readRDS("output/archs4_benchmark/normalized_data_sparse.rds")
  
df = norm_expr %>% 
  left_join(design_df, by=c("id", "type")) %>%
  transmute(id, type, contrasts = future_pmap(., .f = function(emat, design, ...) {
    contrasts = makeContrasts(
      con = perturbed - control,
      levels = design
    )
    
    lmFit(emat, design) %>% 
      contrasts.fit(contrasts) %>%
      eBayes() %>%
      tidy() %>%
      select(gene, logfc = estimate)
  }, .progress = T)) %>%
  unnest()

saveRDS(df, "output/archs4_benchmark/contrasts.rds")
```

#### Run VIPER on contrast
```{r "run viper on contrast"}
contrasts = readRDS("output/archs4_benchmark/contrasts.rds") %>%
  nest(-type)
human_dorothea = read_csv("data/regulons/dorothea/dorothea_regulon_human_v1.csv")

viper_scores = contrasts %>%
  transmute(type, viper_result = data %>% map(run_viper, 
                                              regulon = human_dorothea, 
                                              value_name = "logfc", 
                                              id_name = "id")) %>%
  unnest(viper_result)

saveRDS(viper_scores, "output/archs4_benchmark/viper_scores_sparse.rds")
```

#### RUN VIPER on single samples
```{r "run viper on single samples}
norm_expr = readRDS("output/archs4_benchmark/normalized_data_sparse.rds")
human_dorothea_viper_format = read_csv("data/regulons/dorothea/dorothea_regulon_human_v1.csv") %>%
  df2regulon()

# # consider only experiments where the perturbed TF belongs to confidence class A
# exp = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
#   distinct(id, target, confidence) %>%
#   filter(confidence == "A") %>%
#   select(id)

ss_viper_scores = norm_expr %>% 
  filter(type == "single_cells") %>%
  #semi_join(exp) %>%
  transmute(id, type, 
            ss_viper_result = emat %>% future_map(
              ~viper(
                eset = as.matrix(.x),
                regulon = human_dorothea_viper_format,
                nes = T, 
                method = "scale",
                minsize = 4,
                eset.filter = F, 
                adaptive.size = F), .progress = T ))

saveRDS(ss_viper_scores, "output/archs4_benchmark/ss_viper_scores.rds")

```
#### Performance evaluation
```{r "performance evaluation"}
viper_scores = readRDS("output/archs4_benchmark/viper_scores_sparse.rds")
meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
  select(target, perturbation, id)

df = viper_scores %>% left_join(meta, by="id")

design = tribble(
  ~confidence, ~group,
  "A", "single_conf",
  "B", "single_conf",
  "C", "single_conf",
  "D", "single_conf",
  "E", "single_conf",
  "A", "multi_conf",
  "AB", "multi_conf",
  "ABC", "multi_conf",
  "ABCD", "multi_conf",
  "ABCDE", "multi_conf"
) %>%
  mutate(viper_scores=list(df),
         confidence = factor(confidence, levels=c("A", "B", "C", "D", "E",
                                                  "AB", "ABC", "ABCD", 
                                                  "ABCDE")))

performance = design %>%
  transmute(
    group, confidence, input = pmap(., .f = function(confidence, viper_scores, ...) {
      conf_levels = str_split(confidence, "") %>% 
        pluck(1)
      
      coverage = viper_scores %>% 
        filter(confidence %in% conf_levels) %>%
        filter(tf == target) %>%
        distinct(tf) %>%
        nrow()
      
      viper_scores %>%
        filter(confidence %in% conf_levels) %>%
        mutate(response = case_when(tf == target ~ 1,
                                    TRUE ~ 0),
               response = factor(response, levels = c("1", "0")),
               predictor = case_when(perturbation == "inhibition" ~ -1 * activity,
                                     perturbation == "activation" ~ activity),
               coverage = coverage) %>%
        select(type, response, predictor, coverage)
  })) %>%
  unnest(input)
  
meta_performance = performance %>%
  count(group, confidence, type, response, coverage) %>%
  spread(response, n) %>%
  rename(positive = `1`, negative = `0`) %>%
  mutate(random = positive/(positive + negative))

# NOTE: "direction" from pROC::roc() is not defined in multi metric setup
multi_metric = metric_set(roc_auc, pr_auc)


performance_result = performance %>% 
  group_by(confidence, group, type) %>%
  multi_metric(response, predictor) %>%
  left_join(meta_performance, by = c("confidence", "group", "type")) %>%
  rename(metric = .metric, auc = .estimate) %>%
  select(-.estimator) %>%
  mutate(random = case_when(metric == "roc_auc" ~ 0.5,
                            TRUE ~  random),
         label = case_when(type == "bulk_sample" ~ str_c("bulk", confidence, sep = "_"),
                           type == "single_cells" ~ str_c("sc", confidence, sep="_")))

# check if multi metric can be used eventhough "direction" is not specified
single_metric_res = performance %>% 
  group_by(confidence, group, type) %>%
  roc_auc(response, predictor, options=list(direction = "<"))

to_check = stopifnot(single_metric_res %>%
                       arrange(confidence, group, type) %>% 
                       pull(.estimate),
                     performance_result %>%
                       arrange(confidence, group, type) %>%
                       filter(metric == "roc_auc") %>%
                       pull(auc))
stopifnot(ncol(to_check) == 6)

input %>% 
  group_by(type, confidence, group) %>%
  roc_curve(response, predictor, options=list(direction = "<")) %>%
  autoplot()

a = performance_result %>%
  filter(metric == "roc_auc") %>%
  ggplot(aes(x=auc,y=coverage, color=type, label=confidence)) +
  geom_point() +
  facet_grid(metric~group, scales="free") + 
  my_theme() +
  #theme(legend.position = "none") +
  geom_vline(aes(xintercept = random), linetype="dashed") +
  geom_text_repel()

b = performance_result %>%
  select(-random) %>%
  spread(metric, auc) %>%
  ggplot(aes(x=roc_auc, y=pr_auc, label=confidence, color=group)) +
  geom_point() +
  geom_text_repel() +
  my_theme() +
  facet_wrap(~type, ncol=1) +
  theme(legend.position = "none")

plot_grid(a,b, labels="AUTO", rel_widths = c(2,1))
```


### EDA
#### Correlation of raw read counts between bulk and single cells
```{r "correlation of raw read counts between bulk and single cells"}
df_raw = readRDS("output/archs4_benchmark/raw_read_counts_sparse.rds")

cor_raw = df_raw %>% 
  spread(type, raw_counts) %>%
  transmute(id, r = future_pmap(., function(bulk_sample, single_cells, ...) {
    bulk = bulk_sample %>%
      data.frame(check.names = F, stringsAsFactors = F) %>%
      rownames_to_column("gene") %>% 
      gather(sample, count, -gene) %>%
      as_tibble()

    sc = single_cells %>%
      as.matrix() %>%
      data.frame(check.names = F, stringsAsFactors = F) %>%
      rownames_to_column("gene") %>%
      gather(cell, count, -gene) %>%
      as_tibble() %>%
      separate(cell, into=c("sample", "tmp", "cell")) %>%
      select(-tmp) %>% 
      group_by(sample, gene) %>%
      summarise(mean_count = mean(count)) %>%
      ungroup()
    
    left_join(bulk, sc, by = c("gene", "sample")) %>%
      group_by(gene) %>%
      mutate(r = cor(count,mean_count)) %>%
      ungroup() %>%
      distinct(gene, r)
  }, .progress = T))

cor_raw %>%
  unnest(r) %>%
  ggplot(aes(x=r)) +
  geom_histogram() +
  facet_wrap(~id, scales="free")

cor_raw %>%
  unnest(r) %>%
  ggplot(aes(x="",y=r)) +
  geom_violin() +
  my_theme()
```

#### Correlation of normalized expression between bulk and single cells
```{r "correlation of normalized expression between bulk and single cells"}
df_norm = readRDS("output/archs4_benchmark/normalized_data.rds")

dat_norm = df_norm %>% 
  unnest(emat) %>%
  group_by(id, sample, type, gene) %>%
  summarise(mean_expression = mean(expression)) %>%
  ungroup() %>%
  spread(type, mean_expression)

gene_cor_norm = dat_norm %>%
  group_by(id, gene) %>%
  summarise(r = cor(bulk_sample, single_cells)) %>%
  ungroup()

gene_cor_norm %>%
  ggplot(aes(x=r)) +
  geom_histogram(color="white", bins=41) +
  facet_wrap(~id, ncol = 5, scales="free") +
  my_theme() +
  xlab("Correlation coefficient")

# example genes
dat_norm %>%
  filter((id == "archs:0003" & gene == "IGSF3") |
         (id == "archs:0002" & gene == "A3GALT2")) %>%
  ggplot(aes(x=bulk_sample, y=single_cells)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~gene+id, scales="free") +
  my_theme()
```

#### Correlation of logFCs between bulk and single cell
```{r "correlation of logFC between bulk and single cell}
contrasts = readRDS("output/archs4_benchmark/contrasts.rds")

cor_log = contrasts %>% 
  spread(type, logfc) %>%
  group_by(id) %>%
  mutate(r = cor(bulk_sample, single_cells)) %>%
  ungroup() %>%
  distinct(id, r)

cor_log %>%
  ggplot(aes(x=r)) +
  geom_histogram(bins=20, color="white") +
  my_theme()

contrasts %>% 
  spread(type, logfc) %>%
  ggplot(aes(x=bulk_sample, y = single_cells)) +
  geom_point() +
  facet_wrap(~id, scales="free") +
  geom_smooth(method="lm") +
  my_theme()

```

#### Correlation of VIPER scores between bulk ans single cell
```{r "correlation of viper scores between bulk and single cells}
ss_viper_scores = readRDS("output/archs4_benchmark/ss_viper_scores.rds")

cor_viper = ss_viper_scores %>% 
  spread(type, ss_viper_result) %>%
  transmute(id, r = future_pmap(., function(bulk_sample, single_cells, ...) {
    bulk = bulk_sample %>%
      data.frame(check.names = F, stringsAsFactors = F) %>%
      rownames_to_column("tf") %>% 
      gather(sample, activity, -tf) %>%
      as_tibble()

    sc = single_cells %>%
      as.matrix() %>%
      data.frame(check.names = F, stringsAsFactors = F) %>%
      rownames_to_column("tf") %>%
      gather(cell, activity, -tf) %>%
      as_tibble() %>%
      separate(cell, into=c("sample", "tmp", "cell")) %>%
      select(-tmp) %>% 
      group_by(sample, tf) %>%
      summarise(mean_activity = mean(activity)) %>%
      ungroup()
    
    left_join(bulk, sc, by = c("tf", "sample")) %>%
      group_by(tf) %>%
      mutate(r = cor(activity, mean_activity)) %>%
      ungroup() %>%
      distinct(tf, r)
  }, .progress = T))

cor_viper %>%
  unnest(r) %>%
  ggplot(aes(x=r)) +
  geom_histogram() +
  facet_wrap(~id, scales="free")

cor_viper %>%
  unnest(r) %>%
  ggplot(aes(x="",y=r)) +
  geom_violin() +
  my_theme()
```

#### Relationship between library size and non-zero-genes in single cells
```{r "relationship between library size and non-zero-genes in single cells"}
df_raw = readRDS("output/archs4_benchmark/raw_read_counts.rds")

rel_raw = df_raw %>% 
  filter(type == "single_cells") %>%
  unnest(raw_counts) %>%
  filter(count != 0) %>%
  group_by(id, sample, cell) %>%
  summarise(libsize = sum(count), non_zero_genes = n())

rel_raw %>% 
  ggplot(aes(x=libsize, y=non_zero_genes, color=id)) +
  geom_point() +
  my_theme() +
  labs(x="Library size", y="Number of non-zero-genes")

rel_raw %>% ggplot(aes(x=libsize)) +
  geom_density() +
  facet_wrap(~id) +
  my_theme()
```

#### Distribution of single cell raw read counts
```{r "distribution of single cell raw read counts"}
df_raw = readRDS("output/archs4_benchmark/raw_read_counts.rds")

read_dist = df_raw %>% filter(type == "single_cells") %>%
  unnest(raw_counts)

# low - median - high library size
read_dist %>%
  filter(cell %in%  c("CHNLEUQV", "OHPFMDKQ", "ZJSDMONF")) %>%
  ggplot(aes(x=log10(count+1), label=cell)) +
  geom_density() +
  facet_wrap(~id+cell, scales="free") +
  my_theme() 

read_dist %>% group_by(cell) %>% tally(count) %>% arrange(n) %>% filter(cell %in%  c("CHNLEUQV", "OHPFMDKQ", "ZJSDMONF"))

```

#### Check if perturbation was sucessuful
```{r "check if perturbation was successful"}
df_contrast = readRDS("output/archs4_benchmark/contrasts.rds")
meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
  select(target, id, perturbation, accession)

qc_df = df_contrast %>% 
  filter(type == "bulk_sample") %>%
  left_join(meta) %>%
  filter(gene == target) 

qc_df %>%
  ggplot(aes(x=fct_reorder(id, logfc), y=logfc, color=perturbation)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  my_theme() 
```

#### Benchmark coverage with respect to DoRothEA confidence level
```{r "benchmark coverage with respect to dorothea confidence level"}
meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
  select(target, id, confidence)
anno = readRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds") %>%
  distinct(id)

c = inner_join(meta, anno, by="id") %>% 
  rename(tf = target) %>%
  count(confidence) %>%
  ggplot(aes(x="DoRothEA Confidence", y=n, fill=confidence)) +
  geom_bar(stat="identity", 
           position = position_stack(reverse = TRUE)) +
  my_theme() +
  theme(axis.title.x = element_blank()) +
  labs(y = "# perturbation targets per confidence level")
```
### Clustering
#### Experiment-wise clustering based on single sample normalized expression 
```{r "experiment-wise clustering based on normalized expression}
norm_expr = readRDS("output/archs4_benchmark/normalized_data_sparse.rds")
anno = readRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds") %>%
  nest(-c(id, type), .key="meta")

# # experiments with target tf accompanied with confidence A
# exp_of_interest = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
#   filter(confidence == "A") %>%
#   dplyr::select(id) %>%
#   semi_join(anno)

set.seed(12345)
norm_tsne = norm_expr %>% 
  left_join(anno) %>%
  filter(type == "single_cells") %>%
  transmute(id, type, coords = future_pmap(., function(id, type, emat, meta, ...) {
    
    message(id, " - ", type)
    stopifnot(colnames(emat) == meta$cell)
    
    tsne_object = emat %>%
      t() %>%
      as.matrix() %>%
      Rtsne()


    coords = tsne_object %>%
      pluck("Y") %>%
      as_tibble() %>%
      mutate(sample = meta$sample,
             group = meta$group,
             cell = meta$cell) %>%
      select(cell, V1, V2, sample, group)
  }, .progress = T))

saveRDS(norm_tsne, "output/archs4_benchmark/experiment_tsne_norm_expression.rds")
```

#### Experiment-wise clustering based on single sample viper scores
```{r "experiment-wise clustering based on single sample viper scores}
ss_viper_scores = readRDS("output/archs4_benchmark/ss_viper_scores.rds")

anno = readRDS("data/archs4_benchmark/meta_data/tidy_sample_anno.rds") %>%
  nest(-c(id, type), .key="meta")

set.seed(12345)
viper_tsne = ss_viper_scores %>% 
  left_join(anno) %>%
  filter(type == "single_cells") %>%
  transmute(id, type, coords = future_pmap(., function(id, type, ss_viper_result, meta, ...) {
    message(id, " - ", type)
    stopifnot(colnames(ss_viper_result) == meta$cell)
    
    tsne_object = ss_viper_result %>%
      t() %>%
      as.matrix() %>%
      Rtsne()
    
    coords = tsne_object %>%
      pluck("Y") %>%
      as_tibble() %>%
      mutate(sample = meta$sample,
             group = meta$group,
             cell = meta$cell) %>%
      select(cell, V1, V2, sample, group)
  }, .progress = T))

saveRDS(viper_tsne, "output/archs4_benchmark/experiment_tsne_viper_scores.rds")
```

#### Silhouettes
```{r "shilhouettes}
viper_tsne = readRDS("output/archs4_benchmark/experiment_tsne_viper_scores.rds") %>%
  mutate(class = "viper_scores")

norm_tsne = readRDS("output/archs4_benchmark/experiment_tsne_norm_expression.rds") %>%
  mutate(class = "normalized_expression")



sil_res = bind_rows(norm_tsne, viper_tsne) %>%
  transmute(id, type, class, sil = coords %>% map(function(mat) {
    cluster_vec = mat %>%
      distinct(cell, group, sample) %>%
      mutate(group = as_factor(group),
             sample = as_factor(sample),
             cluster_group_id = as.integer(group),
             cluster_sample_id = as.integer(sample))

    meta_cluster = cluster_vec %>%
      distinct(group, sample, cluster_group_id, cluster_sample_id) %>%
      mutate_if(is.integer, as.character)
    
    stopifnot(mat$cell == cluster_vec$cell)
    dist_mat = mat %>%
      select_if(is.numeric) %>%
      dist()
    
    s_group = silhouette(cluster_vec$cluster_group_id, dist_mat) %>%
      summary()
    s_sample = silhouette(cluster_vec$cluster_sample_id, dist_mat) %>%
      summary()
    
    clus_avg_widths_group = s_group %>%
      pluck("clus.avg.widths") %>%
      enframe("cluster_group_id", "avg_width") %>%
      inner_join(meta_cluster) %>%
      distinct(group, avg_width) %>%
      mutate(mean_avg_width = mean(avg_width)) %>%
      mutate(cluster_ref = "group")
    
    clus_avg_widths_sample = s_sample %>%
      pluck("clus.avg.widths") %>%
      enframe("cluster_sample_id", "avg_width") %>%
      inner_join(meta_cluster) %>%
      distinct(group,sample, avg_width) %>%
      mutate(mean_avg_width = mean(avg_width)) %>%
      mutate(cluster_ref = "sample")
    
    bind_rows(clus_avg_widths_group, clus_avg_widths_sample) %>%
      select(cluster_ref, group, sample, avg_width, mean_avg_width)
  }))


saveRDS(sil_res, "output/archs4_benchmark/silhouette_results.rds")

```

#### Silhouette visulization
```{r "silhouette visulization}
sil_res = readRDS("output/archs4_benchmark/silhouette_results.rds") 
meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
  distinct(id, confidence)


sil_res %>%
  left_join(meta, by="id") %>%
  unnest(sil) %>%
  filter(cluster_ref == "group") %>%
  distinct(id, type, class, cluster_ref, mean_avg_width, confidence) %>%
  ggplot(aes(x=interaction(class, cluster_ref), y=mean_avg_width)) +
  geom_hline(yintercept = 0, linetype="dashed") +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  geom_jitter(height = 0, width = 0.1, alpha=.5) +
  coord_flip() +
  my_theme() +
  facet_wrap(~confidence)

sil_res %>%
  unnest(sil) %>%
  filter(cluster_ref == "group") %>%
  ggplot(aes(x=interaction(group, class), y=avg_width)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  geom_jitter(height = 0, width = 0.1, alpha=.5) +
  my_theme() +
  coord_flip()

## correlation of silhouette scores between expression and footprint scores
sil_res %>%
  unnest(sil) %>%
  filter(cluster_ref == "group") %>%
  left_join(meta) %>%
  distinct(id, type, class, group, avg_width, confidence) %>%
  spread(class, avg_width) %>%
  ggplot(aes(x=normalized_expression, y=viper_scores)) +
  geom_point(aes(color=confidence)) +
  geom_abline(linetype="dashed") +
  lims(x=c(0,1), y=c(0,1)) +
  my_theme() +
  facet_wrap(~group) +
  geom_smooth(method = "lm")

# correlation of silhouette scores between cluster types of normalized expresion
sil_res %>%
  left_join(meta, by="id") %>%
  filter(class == "normalized_expression") %>%
  unnest(sil) %>%
  distinct(id, type, class, cluster_ref, mean_avg_width, confidence) %>%
  spread(cluster_ref, mean_avg_width) %>%
  ggplot(aes(x=group, y=sample)) +
  geom_point(aes(color=confidence)) +
  geom_abline(linetype="dashed") +
  geom_smooth(method="lm") +
  my_theme()
```

#### Cluster visalization
```{r "cluster visulaization}
norm_tsne = readRDS("output/archs4_benchmark/experiment_tsne_norm_expression.rds") %>%
  mutate(class = "normalized_expression")

viper_tsne = readRDS("output/archs4_benchmark/experiment_tsne_viper_scores.rds") %>%
  mutate(class = "viper_scores")

tsne = bind_rows(norm_tsne, viper_tsne)
sil_res = readRDS("output/archs4_benchmark/silhouette_results.rds") %>%
  unnest(sil) %>%
  distinct(id, type, class, cluster_ref, mean_avg_width)

pos_example =  sil_res %>%
  group_by(type, class, cluster_ref) %>%
  top_n(1, mean_avg_width) %>%
  ungroup() %>%
  mutate(example = "positive")

neg_example = sil_res %>%
  group_by(type, class, cluster_ref) %>%
  top_n(1, -mean_avg_width) %>%
  ungroup() %>%
  mutate(example = "negative")

examples = bind_rows(pos_example, neg_example)

g = tsne %>% 
  unnest(coords) %>%
  inner_join(examples, by=c("id", "type", "class")) %>% 
  mutate(example = factor(example, levels=c("positive", "negative"))) %>%
  filter(cluster_ref == "group") %>%
  ggplot(aes(x=V1, y=V2, color=group)) +
  geom_point() +
  facet_wrap(~example+class+cluster_ref+id, scales="free") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank()) +
    my_theme()

s = tsne %>% 
  unnest(coords) %>%
  inner_join(examples, by=c("id", "type", "class")) %>% 
  mutate(example = factor(example, levels=c("positive", "negative"))) %>%
  filter(cluster_ref == "sample") %>%
  ggplot(aes(x=V1, y=V2, color=sample)) +
  geom_point() +
  facet_wrap(~example+class+cluster_ref+id, scales="free") +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank()) +
    my_theme()

plot_grid(g, s)
```

### Misc
#### Comparsion of limma vs direct calculation of logFC
```{r "comparison of limma vs direct calcualtion of logfc}
d = readRDS("output/archs4_benchmark/contrasts_sparse.rds") %>%
  mutate(logfc = round(logfc, 8)) %>%
  arrange(id, type, gene)
l = readRDS("output/archs4_benchmark/contrasts_limma.rds") %>%
  mutate(logfc = round(logfc, 8)) %>%
  arrange(id, type, gene)

identical(d,l) # FALSE
anti_join(d,l)
anti_join(l,d)

sum(d$logfc != l$logfc)
idx = which(d$logfc != l$logfc)

d2 = d %>% slice(idx) %>%
  arrange(id, type, gene)
l2 = l %>% slice(idx) %>%
  arrange(id, type, gene)

anti_join(d2, l2)

```

#### Explore effect of mor
```{r "explore effect of mor}
contrasts = readRDS("output/archs4_benchmark/contrasts.rds") %>%
  filter(type == "bulk_sample") %>%
  select(-type) 

meta = readRDS("data/archs4_benchmark/meta_data/meta_df.rds") %>%
  select(target, perturbation, id)


basic_dorothea = read_csv("~/Projects/DoRothEA/data/TFregulons/consensus/table/database.csv") %>%
  select(tf = TF, target, mor=effect, confidence=score) %>%
  filter(tf != target) %>%
  mutate(likelihood = 1) %>%
  rename(default_mor = mor) %>%
  distinct(tf, target, default_mor)

my_basic_dorothea = dorothea_regulon_human_v1 %>%
  inner_join(basic_dorothea, by=c("tf", "target")) %>%
  select(tf, target, confidence, mor =default_mor, likelihood) %>%
  filter(confidence %in% c("A"))

dorothea_all2one = my_basic_dorothea %>%
  mutate(mor = 1)

dorothea_all2zero = my_basic_dorothea %>%
  mutate(mor = 0)

dorothea_all2neg_one = my_basic_dorothea %>%
  mutate(mor = -1)

dorothea_unknown2one = my_basic_dorothea %>%
  mutate(mor = case_when(mor == 0 ~ 1,
                         TRUE ~ mor))

dorothea_unknown2neg_one = my_basic_dorothea %>%
  mutate(mor = case_when(mor == 0 ~ -1,
                         TRUE ~ mor))

design = tribble(
  ~regulon, ~identifier, 
  dorothea_all2one, "dorothea_all2one", 
  dorothea_all2zero, "dorothea_all2zero",
  dorothea_all2neg_one, "dorothea_all2neg_one",
  dorothea_unknown2one, "dorothea_unkown2one",
  dorothea_unknown2neg_one, "dorothea_unkown2neg_one",
  my_basic_dorothea, "dorothea_unknown2zero"
) %>%
  mutate(id_name = "id",
         value_name = "logfc",
         E = list(contrasts))

viper_scores = design %>%
  transmute(identifier, activity = pmap(., .f=run_viper)) %>%
  unnest(activity) %>%
  left_join(meta)
    
input = viper_scores %>%
  mutate(response = case_when(tf == target ~ 1,
                        TRUE ~ 0),
         response = factor(response, levels = c("1", "0")),
         predictor = case_when(perturbation == "inhibition" ~ -1 * activity,
                               perturbation == "activation" ~ activity)) %>%
  select(identifier, response, predictor)

input %>%
  group_by(identifier) %>%
  roc_auc(response, predictor, options=list(direction = "<"))
```

#### Explore VIPER and aREA
```{r "explore viper and area}
eset = readRDS("output/archs4_benchmark/contrasts.rds") %>%
  filter(type == "bulk_sample") %>%
  select(-type) %>%
  spread(id, logfc) %>%
  column_to_rownames("gene")

regulon = read_csv("~/Projects/DoRothEA/data/TFregulons/consensus/table/database.csv") %>%
  select(tf = TF, target, mor=effect, confidence=score) %>%
  filter(tf != target) %>%
  mutate(likelihood = 1) %>%
  select(-confidence) %>%
  df2regulon()

nes = T
method = "none"
minsize = 4
eset.filter = F 
adaptive.size = F
dnull = NULL
pleiotropy = FALSE
mvws = 1
pleiotropyArgs = list(regulators = 0.05, shadow = 0.05, targets = 10, penalty = 20, method = "adaptive")
cores = 1
verbose = TRUE
bootstraps = 0
```

### Text mining to extract PROGENy benchmark data
#### Read GSM meta data from ARCHS4
```{r "read gsm meta data from archs4}
meta = get(load("data/archs4_benchmark/meta_data/human_gsm_meta.rda")) %>%
  compact()
# position is empty 124891
series_sample_mapping = meta %>%
  future_map_dfr(function(x) {
    tibble(series = x$Sample_series_id,
           sample = x$Sample_geo_accession)
  }, .progress=T)

meta_df = meta %>% 
  future_imap_dfr(function(a,b) {
    a %>% 
      enframe("key", "text") %>%
      mutate(sample = b)
}, .progress = T) %>%
  filter(key %in% c("Sample_title","Sample_description", 
                    "Sample_data_processing", "Sample_source_name_ch1", 
                    "Sample_characteristics_ch1")) %>%
  unnest(text) %>%
  unnest_tokens(word, text) %>%
  inner_join(series_sample_mapping, by="sample") %>%
  select(series, sample, key, word)

saveRDS(meta_df, "output/archs4_benchmark/tidy_gsm_text.rds")
```

#### Overview of meta data text
```{r "Overview of meta data text"}
meta_df = readRDS("output/archs4_benchmark/tidy_gsm_text.rds")

#num samples per series
samples_per_series = meta_df %>%
  distinct(series, sample) %>%
  count(series, name = "m") %>%
  filter(m>3)

lexica = read_delim("data/archs4_benchmark/meta_data/word_pathway_association.csv", delim = ";")
x = meta_df %>% 
  anti_join(stop_words) %>%
  inner_join(lexica) %>%
  distinct(series, word, pathway) %>%
  count(series, pathway, sort=T) %>%
  inner_join(samples_per_series) %>%
  mutate(importance = n/m) %>%
  arrange(-importance)


```

### Test other simulation strategies
```{r "test other simulation strategies"}
tpm_mat = readRDS("output/transcript_downsampling/tpm_mat.rds")
df = tpm_mat %>% 
  mutate(gene = as_factor(gene)) %>%
  nest(-sample, .key=bulk_sample) %>% 
  slice(1:30) 

set.seed(1)
res = df %>%
  mutate(capture_prob = 0.1, num_cells = 100) %>%
  mutate(single_cells = pmap(., .f = generate_single_cells)) %>%
  gather(type, df, bulk_sample, single_cells)

# relationship library size - number of non-zero-genes
rel = res %>% 
  filter(type == "single_cells") %>%
  unnest() %>%
  filter(tpm != 0) %>%
  group_by(sample, cell) %>%
  summarise(libsize = sum(tpm), non_zero_genes = n()) %>%
  ungroup()

rel %>%
  ggplot(aes(x=libsize, y=non_zero_genes, color=sample)) +
  geom_point()

# distribution of a single cell
res %>% 
  filter(type == "single_cells") %>%
  slice(1) %>%
  unnest() %>%
  filter(cell == "5") %>%
  ggplot(aes(x=log10(tpm+1))) +
  geom_density()
```

### Explanatory figures for presentations
```{r "explanatory figures for presentations}
norm_tsne = readRDS("output/archs4_benchmark/experiment_tsne_norm_expression.rds") %>%
  filter(id %in% c("archs:0099", "archs:0044")) %>%
  unnest()

group = norm_tsne %>% 
  filter(id == "archs:0099") %>%
  ggplot(aes(x=V1, y=V2, color=group)) +
  geom_point() +
  facet_wrap(~id) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        legend.position = "none") +
  my_theme()

sample = norm_tsne %>% 
  filter(id == "archs:0099") %>%
  ggplot(aes(x=V1, y=V2, color=sample)) +
  geom_point() +
  facet_wrap(~id) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.title = element_blank(),
        legend.position = "none") +
  my_theme()

plot_grid(group, sample, nrow=2)
```